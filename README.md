

This repository contains both **Assignment 1 (RAG Prototype)** and **Assignment 2 (Evaluation Framework)** for the **AI Intern Hiring Task** at **Kalpit Pvt Ltd, UK**.

The project implements a **complete Retrieval-Augmented Generation (RAG) system** using:

- **LangChain (LCEL)**
- **ChromaDB** (local vector store)
- **HuggingFace sentence-transformers**
- **Ollama + Mistral 7B** (local LLM)
- Python 3.11+

The system loads Ambedkarâ€™s writings, builds embeddings locally, retrieves relevant chunks, and generates answers via a local LLM.  
The evaluation framework computes **retrieval quality**, **answer quality**, **semantic similarity**, and **chunking performance** across a test dataset.

---

# ğŸ“‚ Project Structure

```

â”œâ”€â”€ main.py                  # Interactive RAG system (Assignment 1)
â”œâ”€â”€ utils.py                 # Embedding, ingestion, retrieval functions
â”œâ”€â”€ evaluation.py            # Full evaluation pipeline (Assignment 2)
â”œâ”€â”€ corpus/                  # 6 Ambedkar documents for evaluation
â”‚   â”œâ”€â”€ speech1.txt
â”‚   â”œâ”€â”€ speech2.txt
â”‚   â”œâ”€â”€ speech3.txt
â”‚   â”œâ”€â”€ speech4.txt
â”‚   â”œâ”€â”€ speech5.txt
â”‚   â””â”€â”€ speech6.txt
â”œâ”€â”€ test_dataset.json        # 25 evaluation questions with ground truth
â”œâ”€â”€ speech.txt               # Input speech for Assignment 1
â”œâ”€â”€ test_results.json        # Auto-generated evaluation outputs
â”œâ”€â”€ results_analysis.md      # Auto-generated analysis summary
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # You are here

````

---

# ğŸ§© **Assignment 1 â€” RAG Prototype**

## âœ” Features

- Loads **speech.txt** (Ambedkar excerpt)
- Splits text into chunks
- Creates local embeddings using **sentence-transformers/all-MiniLM-L6-v2**
- Stores vectors in **ChromaDB**
- Uses **LCEL pipeline** with `ChatOllama` for generation
- Performs retrieval using Chroma retriever
- Interactive CLI loop for Q&A  
- Type **exit** to quit

---

# â–¶ **Run Assignment 1 (main.py)**

### 1ï¸âƒ£ **Create Virtual Environment**

```bash
python -m venv venv
.\venv\Scripts\activate   # Windows
````

### 2ï¸âƒ£ **Install Dependencies**

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Install Ollama + Mistral**

```bash
ollama pull mistral
ollama serve
```

### 4ï¸âƒ£ **Run RAG System**

```bash
python main.py
```

### ğŸ“ Example Session

```
ChromaDB not found. Running ingestion...
RAG system ready!

Your question: What is the remedy for caste?
=== ANSWER ===
...
Your question: exit
Exiting...
```

---

# ğŸ§ª **Assignment 2 â€” Evaluation Framework**

You must evaluate the RAG system on:

### ğŸ“„ **Document Corpus**

6 files in `/corpus`

### ğŸ“ **Test Dataset**

25 Q&A pairs in `test_dataset.json`

---

## ğŸ”¬ Evaluation Includes

### **1. Retrieval Metrics**

* Hit Rate
* Mean Reciprocal Rank (MRR)
* Precision@K

### **2. Answer Quality Metrics**

* ROUGE-L
* BLEU
* Cosine Similarity
* Answer Relevance
* Faithfulness

### **3. Semantic Metrics**

* Embedding similarity (SentenceTransformer)

### **4. Chunking Strategies Compared**

* **Small**: ~250 chars
* **Medium**: ~550 chars
* **Large**: ~900 chars

### **5. Outputs**

* **test_results.json**
* **results_analysis.md**

---

# â–¶ **Run Assignment 2 (evaluation.py)**

Make sure Ollama is running:

```bash
ollama serve
```

Run evaluation:

```bash
python evaluation.py
```

This will:

* Build 3 Chroma vector stores
* Run **75 LLM Q&A calls** (25 questions Ã— 3 chunk sizes)
* Compute all metrics
* Save:

```
test_results.json
results_analysis.md
```

---

# ğŸ’¡ **How the Evaluation Pipeline Works**

1. Load all 6 documents
2. Build three vector stores (small/medium/large chunks)
3. For each chunking strategy:

   * Retrieve top-K documents
   * Generate answer using LCEL chain
   * Compute all metrics
   * Save results
4. Compare chunk sizes
5. Produce human-readable summary

---

# ğŸ§  **Technologies Used**

### ğŸ“š LangChain (LCEL)

* `ChatPromptTemplate`
* `RunnablePassthrough`
* `ChatOllama`
* `StrOutputParser`

### ğŸ” Vector Search

* **ChromaDB**

### ğŸ”¤ Embeddings

* `sentence-transformers/all-MiniLM-L6-v2`

### ğŸ¤– Local LLM

* **Ollama Mistral 7B**

### ğŸ“Š Evaluation Tools

* ROUGE
* BLEU (NLTK)
* Cosine similarity
* SentenceTransformer embeddings
* scikit-learn

---

# ğŸ“ˆ **Results Files**

### **test_results.json**

Contains retrieved sources, generated answers, and all metric scores.

### **results_analysis.md**

Contains final summary, best chunk size, and evaluation insights.

---

# ğŸ **Final Notes**

* Fully offline RAG + evaluation
* No API keys required
* Uses LCEL (not RetrievalQA) as requested
* Metrics and evaluation strictly follow assignment specification

---

# âœï¸ **Author**

Submission for **Kalpit Pvt Ltd â€“ AI Intern Hiring Task**
Developed by: **Devam Singh**

